{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "79vG5A3a5Dho",
        "gcKIbdwWLi8A",
        "x8p5My8Y6A8G",
        "jCoUBBILLsrx",
        "N1xTJJnpkeGu",
        "Fg9XHyneLpPb",
        "X4YG4U2Hn6at",
        "v_YdOHL3oGlZ",
        "qYojjkMbtjrc",
        "7hDF24AbphL1",
        "6Daox8BNwSPc",
        "XqC-Cxxawy8r",
        "cU0hWRbRnpTR",
        "SOycpx4lxW-I",
        "3Vt6-oiO3X3_",
        "0SmLImgJ5FFH",
        "VYTQUWnj88tD",
        "2uhUq_hM5Mgp",
        "WK9vmTpZ6s0U",
        "lMjexNL18rKU",
        "QWP_VZL3BYPo",
        "XuMnDlG98t52",
        "alMai93gA2D5",
        "qWlmejXSB52M",
        "x60xZ8y9CIph",
        "6ep_SwK9CJnh",
        "UNj14x1qCJ-U",
        "pjuNYI2V2JYg",
        "PSDjM_gGKKBO",
        "RcBtblWpasGG",
        "VbOs9Udmc5m2",
        "KXJ4BoerdtFe",
        "Et9e_WyAd-M1",
        "An9LuoEvevYI",
        "3_IeuhF_fqlF",
        "fHlFe2Jk2voe",
        "kGl9JwlOgkwJ",
        "VLM3xWP6iEX3",
        "46IVtxbxjJPo",
        "3Wf1KridjXxn",
        "Y-EFIe6ukQ-d",
        "GpxC6gpCkdgX",
        "YfPL1S7Ykqav",
        "toounobSk707",
        "2Vxtw2vh3MKT",
        "Hl1qLHS3lKmm",
        "tFLu1C3_koMw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divya-medarametla/CMPE-255-Credit_Hazard-Forecasting/blob/main/CMPE_255_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPORTS"
      ],
      "metadata": {
        "id": "79vG5A3a5Dho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit Hazard Forecasting"
      ],
      "metadata": {
        "id": "Nlfsp6YotdNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Banks lose a significant amount of money as a result of credit defaults, and it is ultimately ordinary customers who bear the brunt of this error. Credit Risk Analysis is used by banks to ensure that credit is supplied to a trustworthy consumer. Credit risk is defined as the risk of defaulting on a loan as a result of the borrower's failure to make mandatory debt payments on time. The lender assumes this risk because the lender loses both the capital and the interest on the loan.\n",
        "\n",
        "Machine Learning-based credit risk analysis eliminates the time-consuming human process of assessing numerous criteria and conditions on which credit can be granted. In the process, it also eliminates the human factor of mathematical mistake and corruption.\n",
        "\n",
        "From this project we aim to build a model to predict whether a person is eligible to get a credit or not. The decision depends on his/her banking history and other parameters mentioned below."
      ],
      "metadata": {
        "id": "3eid6B_ktfN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Set"
      ],
      "metadata": {
        "id": "OrgSEs8zugGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we are using has data for 32,581 borrowers and 12 features related to each of them. Below listed are the features.\n",
        "\n",
        "From the dataset, we can see that the 'loan_status' is the target variable with '1' - the borrower will default on the loan and '0' - the borrower will not.\n",
        "\n",
        "Numerical Vairables:\n",
        "person_age, person_income, person_emp_length, loan_amnt, loan_int_rate, loan_percent_income, cb_preson_cred_hist_length.\n",
        "\n",
        "Categorical Variables:\n",
        "person_home_ownership, loan_intent, loan_grade, cb_person_default_on_file, loan_status.\n",
        "\n",
        "In the data, we have missing values from the 'personemplength' and 'loan_int_rate' columns. But the missing values are a small percentage of the data, So we can remove those rows that have the missing values."
      ],
      "metadata": {
        "id": "E2XGKkmZuEtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source Dataset:"
      ],
      "metadata": {
        "id": "zBROK2UfusXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/laotse/credit-risk-dataset"
      ],
      "metadata": {
        "id": "pLPNWv33ut-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9OvGeqRFUsV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "pZ7Y5x-6sAz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "metadata": {
        "id": "r6wQsCgpFrZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pickle"
      ],
      "metadata": {
        "id": "JwfHUtDSwaeH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}